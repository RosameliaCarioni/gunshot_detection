{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import data_handling\n",
    "import denoising"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the elephant listening project \n",
    "general_path = os.path.join('data', 'Clips')\n",
    "\n",
    "# To ensure that both classes have same of samples and to increase the number of gunshots, \n",
    "# I extracted extra data from: https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "background_path = os.path.join('data', 'Sounds_background')\n",
    "guns_path = os.path.join('data', 'Sounds_gunshots')\n",
    "\n",
    "gunshot_files = [os.path.join(general_path, 'pnnn*'), os.path.join(general_path, 'ecoguns*'), os.path.join(guns_path, '*\\.wav')]\n",
    "\n",
    "no_gunshot_files = [os.path.join(general_path, 'other*'), os.path.join(background_path, '*\\.wav')] \n",
    "gunshot = tf.data.Dataset.list_files(gunshot_files) \n",
    "no_gunshot = tf.data.Dataset.list_files(no_gunshot_files) \n",
    "\n",
    "#to see how many files are in each group: \n",
    "#num_elements = tf.data.experimental.cardinality(no_gunshot).numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Add labels to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot = tf.data.Dataset.zip((gunshot, tf.data.Dataset.from_tensor_slices(tf.ones(len(gunshot)))))\n",
    "no_gunshot= tf.data.Dataset.zip((no_gunshot, tf.data.Dataset.from_tensor_slices(tf.zeros(len(gunshot)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Concatenate gunshots and no gunshots into one data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gunshot.concatenate(no_gunshot)\n",
    "data.as_numpy_iterator().next() # see how it looks like "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Shuffle the data such that not all gunshots are followed by gunshots, and similarly with no gunshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'spectogram'\n",
    "data = data.map(data_handling.preprocess(type= type)) # produces a new dataset by applying preprocess to each element of 'data' \n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000) # mixing training samples 1000 at the time  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
