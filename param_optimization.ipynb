{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data from the elephant listening project \n",
    "general_path = os.path.join('data', 'Clips')\n",
    "\n",
    "# To ensure that both classes have same of samples and to increase the number of gunshots, \n",
    "# I extracted extra data from: https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "background_path = os.path.join('data', 'Sounds_background')\n",
    "guns_path = os.path.join('data', 'Sounds_gunshots')\n",
    "\n",
    "gunshot_files = [os.path.join(general_path, 'pnnn*'), os.path.join(general_path, 'ecoguns*'), os.path.join(guns_path, '*\\.wav')]\n",
    "\n",
    "no_gunshot_files = [os.path.join(general_path, 'other*'), os.path.join(background_path, '*\\.wav')] \n",
    "gunshot = tf.data.Dataset.list_files(gunshot_files) \n",
    "no_gunshot = tf.data.Dataset.list_files(no_gunshot_files) \n",
    "\n",
    "#to see how many files are in each group: \n",
    "#num_elements = tf.data.experimental.cardinality(no_gunshot).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and return wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name): \n",
    "    file_contents = tf.io.read_file(file_name) #retuns a string \n",
    "    wave, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # transforms string into actual wav\n",
    "    wave = wave - tf.reduce_mean(wave) # remove the mean \n",
    "    wave = wave / tf.reduce_max(tf.abs(wave)) #normalize \n",
    "    wave = tf.squeeze(wave, axis= -1) #removes axis \n",
    "    #wave = tf.cast(wave * 32768, tf.float32) # value is scaled to look like int16, however, type is kept as float32 for compatibility issues\n",
    "\n",
    "    return wave, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add labels\n",
    "1: gunshot \n",
    "0: no gunshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot = tf.data.Dataset.zip((gunshot, tf.data.Dataset.from_tensor_slices(tf.ones(len(gunshot)))))\n",
    "no_gunshot= tf.data.Dataset.zip((no_gunshot, tf.data.Dataset.from_tensor_slices(tf.zeros(len(gunshot)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concatenate gunshots and no_gunshots into one data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data/Clips/ecoguns953.wav', 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gunshot.concatenate(no_gunshot)\n",
    "data.as_numpy_iterator().next() # see how it looks like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert data into Spectogram \n",
    "Time frequency compromise: \n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio <br>\n",
    "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    # Load data\n",
    "    wave, sr = load_data(file_path)\n",
    "    max_lenght = 80000 # = 10* 8000, this means 10 seconds \n",
    "\n",
    "    # Padding \n",
    "    wave = wave[:max_lenght] #grab first elements up to max(lengths)\n",
    "    zero_padding = tf.zeros(max_lenght - tf.shape(wave), dtype=tf.float32) # pad with zeros what doesn't meet full length \n",
    "    wave = tf.concat([zero_padding, wave],0) \n",
    "\n",
    "    # Create spectogram \n",
    "    # 1. Fast fourier transform \n",
    "    spectrogram = tf.signal.stft(wave, frame_length=256, frame_step=128)  # Paper: 'Automated detection of gunshots in tropical forests using CNN' \n",
    "    # frame_length =  window length in samples\n",
    "    # frame_step = number of samples to step\n",
    "    # 'Time frequency compromise' \n",
    "    # if window size is small: you get good time resolution in exchange of poor frequency resolution \n",
    "\n",
    "    # 2. Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # 3. Tranform it into appropiate format for deep learning model by adding the channel dimension (in this case 1)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shuffle the data such that not all gunshots are followed by gunshots, and similarly with no gunshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess) # calling preprocess method which generates spectograms\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000) # mixing training samples 1000 at the time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract samples and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:20:08.238979: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "iterator = data.as_numpy_iterator()\n",
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    try: \n",
    "        x_temp, y_temp = iterator.next()\n",
    "        x.append(x_temp)\n",
    "        y.append(y_temp)\n",
    "    except Exception:\n",
    "        break \n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.30, random_state=123)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build model with hyperparameter tunning \n",
    "https://keras.io/guides/keras_tuner/getting_started/ <br>\n",
    "https://www.youtube.com/watch?v=6Nf1x7qThR8&ab_channel=GregHogg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input = (624, 129,1)\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Add input layer \n",
    "    #matching samples.shape\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters= hp.Int(\"conv_filters_0\", min_value=16, max_value=128, step=16), \n",
    "            activation= hp.Choice(\"conv_activation_0\", [\"relu\", \"tanh\"]),\n",
    "            kernel_size = (3,3), \n",
    "            input_shape=input\n",
    "        )\n",
    "    ) \n",
    "    model.add(MaxPool2D(pool_size= (2,2)))\n",
    "\n",
    "    # Tune the number of Conv layers \n",
    "    for i in range(hp.Int(\"num_conv_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            Sequential([\n",
    "                layers.Conv2D(\n",
    "                    filters=hp.Int(f\"conv_filters_{i}\", min_value=16, max_value=128, step=16),\n",
    "                    activation=hp.Choice(f\"conv_activation_{i}\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_size=(3,3),\n",
    "                ), \n",
    "                layers.MaxPool2D(pool_size=(2,2)),\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Tune the number of Dense layers and Tune whether to use dropout layer\n",
    "    for i in range(hp.Int(\"num_dense_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                Sequential([\n",
    "                    layers.Dense(\n",
    "                        # Tune number of units separately.\n",
    "                        units=hp.Int(f\"dense_units_{i}\", min_value=50, max_value=600, step=50),\n",
    "                        activation=hp.Choice(f\"dense_activation_{i}\", [\"relu\", \"tanh\"]),\n",
    "                    ), \n",
    "                    layers.Dropout(\n",
    "                        rate=hp.Float(f\"dense_dropout_{i}\", min_value = 0, max_value = 1)\n",
    "                    )\n",
    "                ]) \n",
    "            )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "        units=1, #because we have 2 classes \n",
    "        activation=hp.Choice(\"activatio_last_layer\", [\"softmax\", \"sigmoid\"]), \n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    # sampling=\"log\", the step is multiplied between samples.\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "        loss=\"BinaryCrossentropy\", \n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x171248760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize tuner by specifying different arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\", # we want maximize accuracy \n",
    "    max_trials= 10, #10 is default\n",
    "    overwrite=True,\n",
    "    directory=\"param_optimization\",\n",
    "    project_name=\"first_try\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss', patience=4) \n",
    "# patience refers to number of epochs: if the val loss is not improving fter 4 ephocs, we stop it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During the search, the model is called with different hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "conv_filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "conv_activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "num_conv_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "num_dense_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "dense_units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 600, 'step': 50, 'sampling': 'linear'}\n",
      "dense_activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dense_dropout_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': None, 'sampling': 'linear'}\n",
      "activatio_last_layer (Choice)\n",
      "{'default': 'softmax', 'conditions': [], 'values': ['softmax', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n",
    "# Default search space size: number of hyper parameters that we are tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 38s]\n",
      "val_accuracy: 0.868297278881073\n",
      "\n",
      "Best val_accuracy So Far: 0.940733790397644\n",
      "Total elapsed time: 01h 27m 41s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(np.stack(x_train), np.stack(y_train), epochs=20, validation_data=(np.stack(x_valid), np.stack(y_valid)), callbacks=[stop_early]) #similar to fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in param_optimization/first_try\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 96\n",
      "conv_activation_0: tanh\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 2\n",
      "dense_units_0: 100\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.6282929702246306\n",
      "activatio_last_layer: sigmoid\n",
      "learning_rate: 0.02661877777328162\n",
      "conv_filters_1: 16\n",
      "conv_activation_1: relu\n",
      "conv_filters_2: 16\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 50\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.0\n",
      "Score: 0.940733790397644\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 96\n",
      "conv_activation_0: tanh\n",
      "num_conv_layers: 1\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 450\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.7524207305138727\n",
      "activatio_last_layer: sigmoid\n",
      "learning_rate: 0.0006059003024667506\n",
      "conv_filters_1: 96\n",
      "conv_activation_1: relu\n",
      "conv_filters_2: 64\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 150\n",
      "dense_activation_1: tanh\n",
      "dense_dropout_1: 0.687365422259995\n",
      "dense_units_2: 350\n",
      "dense_activation_2: tanh\n",
      "dense_dropout_2: 0.36742631387364444\n",
      "Score: 0.9031044244766235\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 32\n",
      "conv_activation_0: tanh\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 150\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.23121857943693547\n",
      "activatio_last_layer: sigmoid\n",
      "learning_rate: 0.001284881015274122\n",
      "conv_filters_1: 48\n",
      "conv_activation_1: relu\n",
      "conv_filters_2: 128\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 600\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.06862645456587058\n",
      "dense_units_2: 300\n",
      "dense_activation_2: tanh\n",
      "dense_dropout_2: 0.9506383590334107\n",
      "Score: 0.868297278881073\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 48\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 3\n",
      "num_dense_layers: 2\n",
      "dense_units_0: 350\n",
      "dense_activation_0: tanh\n",
      "dense_dropout_0: 0.34666857879608126\n",
      "activatio_last_layer: sigmoid\n",
      "learning_rate: 0.00032936147468926936\n",
      "conv_filters_1: 32\n",
      "conv_activation_1: tanh\n",
      "conv_filters_2: 32\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 600\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.15130964326391783\n",
      "Score: 0.6519284844398499\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 96\n",
      "conv_activation_0: tanh\n",
      "num_conv_layers: 1\n",
      "num_dense_layers: 1\n",
      "dense_units_0: 100\n",
      "dense_activation_0: tanh\n",
      "dense_dropout_0: 0.7658588051127031\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.001570303585216244\n",
      "Score: 0.5023518204689026\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 64\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 1\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 300\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.7072242735968823\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.03845339681031618\n",
      "conv_filters_1: 32\n",
      "conv_activation_1: tanh\n",
      "conv_filters_2: 32\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 100\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.72554957409358\n",
      "dense_units_2: 50\n",
      "dense_activation_2: relu\n",
      "dense_dropout_2: 0.0\n",
      "Score: 0.5023518204689026\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 32\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 1\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 100\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.6561987363824092\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.08403704745568384\n",
      "conv_filters_1: 48\n",
      "conv_activation_1: tanh\n",
      "conv_filters_2: 96\n",
      "conv_activation_2: tanh\n",
      "dense_units_1: 350\n",
      "dense_activation_1: tanh\n",
      "dense_dropout_1: 0.06363333965172069\n",
      "dense_units_2: 500\n",
      "dense_activation_2: relu\n",
      "dense_dropout_2: 0.8765985809810629\n",
      "Score: 0.5023518204689026\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 80\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 450\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.9572366029304247\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.0024476473234635197\n",
      "conv_filters_1: 48\n",
      "conv_activation_1: tanh\n",
      "conv_filters_2: 48\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 550\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.5064465315324322\n",
      "dense_units_2: 500\n",
      "dense_activation_2: relu\n",
      "dense_dropout_2: 0.19424515044933222\n",
      "Score: 0.5023518204689026\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 32\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 1\n",
      "dense_units_0: 400\n",
      "dense_activation_0: relu\n",
      "dense_dropout_0: 0.8822043068301989\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.016625944825432053\n",
      "conv_filters_1: 32\n",
      "conv_activation_1: tanh\n",
      "conv_filters_2: 128\n",
      "conv_activation_2: tanh\n",
      "dense_units_1: 500\n",
      "dense_activation_1: tanh\n",
      "dense_dropout_1: 0.5197040635934951\n",
      "dense_units_2: 200\n",
      "dense_activation_2: tanh\n",
      "dense_dropout_2: 0.28400972454326756\n",
      "Score: 0.5023518204689026\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 48\n",
      "conv_activation_0: relu\n",
      "num_conv_layers: 2\n",
      "num_dense_layers: 3\n",
      "dense_units_0: 100\n",
      "dense_activation_0: tanh\n",
      "dense_dropout_0: 0.6418628733411654\n",
      "activatio_last_layer: softmax\n",
      "learning_rate: 0.0019892146428191083\n",
      "conv_filters_1: 16\n",
      "conv_activation_1: relu\n",
      "conv_filters_2: 112\n",
      "conv_activation_2: relu\n",
      "dense_units_1: 250\n",
      "dense_activation_1: relu\n",
      "dense_dropout_1: 0.7099592811579377\n",
      "dense_units_2: 150\n",
      "dense_activation_2: relu\n",
      "dense_dropout_2: 0.4115571383147423\n",
      "Score: 0.5023518204689026\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After all of that we don't have a model yet but rather a set of hyper parameters. Let's query the results and create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_filters_0': 96, 'conv_activation_0': 'tanh', 'num_conv_layers': 3, 'num_dense_layers': 2, 'dense_units_0': 100, 'dense_activation_0': 'relu', 'dense_dropout_0': 0.6282929702246306, 'activatio_last_layer': 'sigmoid', 'learning_rate': 0.02661877777328162, 'conv_filters_1': 16, 'conv_activation_1': 'relu', 'conv_filters_2': 16, 'conv_activation_2': 'relu', 'dense_units_1': 50, 'dense_activation_1': 'relu', 'dense_dropout_1': 0.0}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps) #saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/models/assets\n"
     ]
    }
   ],
   "source": [
    "location = 'data/models'\n",
    "model.save(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used: \n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "input = (624, 129, 1) \n",
    "\n",
    "\n",
    "best_model.build(input_shape=input)\n",
    "best_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6930 - accuracy: 0.4570\n",
      "Validation loss: 0.6930\n",
      "Validation accuracy: 0.4570\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on a validation set\n",
    "loss, accuracy = model.evaluate(np.stack(x_valid), np.stack(y_valid))\n",
    "\n",
    "# print the evaluation results\n",
    "print(f'Validation loss: {loss:.4f}')\n",
    "print(f'Validation accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 89ms/step\n",
      "[[0.4972491 ]\n",
      " [0.49556306]\n",
      " [0.48432872]\n",
      " ...\n",
      " [0.49068755]\n",
      " [0.5039698 ]\n",
      " [0.49622053]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(np.stack(x_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4524929444967074"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = [1 if prediction > 0.5 else 0 for prediction in predictions]\n",
    "accuracy = accuracy_score(np.stack(y_valid), y_pred)\n",
    "accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4118\n",
      "Recall: 0.2097\n",
      "F1-score: 0.2779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(np.stack(y_valid), y_pred)\n",
    "recall = recall_score(np.stack(y_valid), y_pred)\n",
    "f1 = f1_score(np.stack(y_valid), y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_thesis_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
