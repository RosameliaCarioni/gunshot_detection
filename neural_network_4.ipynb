{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow_io as tfio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Audio Classifier using denoised data with spectral gating and Mel-Spectograms in db scale \n",
    "https://www.youtube.com/watch?v=ZLIPkmmDJAc&t=1468s&ab_channel=NicholasRenotte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the elephant listening project \n",
    "general_path = os.path.join('data', 'Clips_denoised', 'spectral_gating')\n",
    "\n",
    "# To ensure that both classes have same of samples and to increase the number of gunshots, \n",
    "# I extracted extra data from: https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "background_path = os.path.join('data', 'Sounds_background_denoised', 'spectral_gating')\n",
    "guns_path = os.path.join('data', 'Sounds_gunshots_denoised', 'spectral_gating')\n",
    "\n",
    "gunshot_files = [os.path.join(general_path, 'pnnn*'), os.path.join(general_path, 'ecoguns*'), os.path.join(guns_path, '*\\.wav')]\n",
    "\n",
    "no_gunshot_files = [os.path.join(general_path, 'other*'), os.path.join(background_path, '*\\.wav')] \n",
    "gunshot = tf.data.Dataset.list_files(gunshot_files) \n",
    "no_gunshot = tf.data.Dataset.list_files(no_gunshot_files) \n",
    "\n",
    "#to see how many files are in each group: \n",
    "#num_elements = tf.data.experimental.cardinality(no_gunshot).numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and return wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name): \n",
    "    file_contents = tf.io.read_file(file_name) #retuns a string \n",
    "    wave, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # transforms string into actual wav, output = float32\n",
    "   \n",
    "    wave = wave - tf.reduce_mean(wave) # remove the mean \n",
    "    wave = wave / tf.reduce_max(tf.abs(wave)) #normalize \n",
    "    wave = tf.squeeze(wave, axis= -1) #removes axis \n",
    "    #wave = tf.cast(wave * 32768, tf.float32) # value is scaled to look like int16, however, type is kept as float32 for compatibility issues # TODO: maybe this is not needed? \n",
    "    return wave, sample_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add labels\n",
    "1: gunshot \n",
    "0: no gunshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot = tf.data.Dataset.zip((gunshot, tf.data.Dataset.from_tensor_slices(tf.ones(len(gunshot)))))\n",
    "no_gunshot= tf.data.Dataset.zip((no_gunshot, tf.data.Dataset.from_tensor_slices(tf.zeros(len(gunshot)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concatenate gunshots and no_gunshots into one data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gunshot.concatenate(no_gunshot)\n",
    "data.as_numpy_iterator().next() # see how it looks like "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert data into Mel-spectogram \n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio time frequency compromise <br>\n",
    "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe <br> \n",
    "https://www.tensorflow.org/io/tutorials/audio mel-spectograms \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    # Load data\n",
    "    wave, sr = load_data(file_path)\n",
    "    max_lenght = 80000 # = 10* 8000, this means 10 seconds \n",
    "\n",
    "    # Padding \n",
    "    wave = wave[:max_lenght] #grab first elements up to max(lengths)\n",
    "    zero_padding = tf.zeros(max_lenght - tf.shape(wave), dtype=tf.float32) # pad with zeros what doesn't meet full length \n",
    "    wave = tf.concat([zero_padding, wave],0) \n",
    "\n",
    "    # Create spectogram \n",
    "    # 1. Fast fourier transform \n",
    "    spectrogram = tf.signal.stft(wave, frame_length=256, frame_step=128)  # Paper: 'Automated detection of gunshots in tropical forests using CNN' \n",
    "    # frame_length =  window length in samples\n",
    "    # frame_step = number of samples to step\n",
    "    # 'Time frequency compromise' \n",
    "    # if window size is small: you get good time resolution in exchange of poor frequency resolution \n",
    "\n",
    "    # 2. Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # 3. Convert into mel-spectogram\n",
    "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=16000, mels=128, fmin=0, fmax=4000)\n",
    "\n",
    "    # 4. Convert the mel-spectogram into db scale\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80) \n",
    "\n",
    "    # 5. Tranform it into appropiate format for deep learning model by adding the channel dimension\n",
    "    mel_spectrogram = tf.expand_dims(dbscale_mel_spectrogram, axis=2)\n",
    "    \n",
    "    return mel_spectrogram, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/Clips/ecoguns105.wav' # seems good  \n",
    "\n",
    "mel, label = preprocess(file_name,1)\n",
    "mel.shape # TensorShape([624, 128, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(mel.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'data/Clips/ecoguns1.wav' # bad: pixeled -- and quite a few are the same (1-4)\n",
    "file_name = 'data/Clips/ecoguns105.wav' # seems good  \n",
    "file_name = 'data/Clips/pnnn4.wav'\n",
    "file_name = 'data/Clips/other1.wav'\n",
    "file_name = 'data/Clips_denoised/spectral_gating/ecoguns0.wav'\n",
    "\n",
    "\n",
    "#file_name = 'data/Clips_denoised/gunshots/spectral_gating/ecoguns0.wav'\n",
    "waveform, sr = load_data(file_name)\n",
    "spectrogram, label = preprocess(file_name, '1')\n",
    "\n",
    "# The reason the plot only shows frequencies up to 140 Hz is because the spectrogram is plotted using a log scale,\n",
    "#  which compresses higher frequencies. The pcolormesh function is plotting the spectrogram as a 2D heatmap where \n",
    "# the x-axis represents time and the y-axis represents frequency, and the color represents the magnitude of the spectrogram \n",
    "# at each time-frequency point.\n",
    "\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  t = np.arange(len(waveform)) / 8000\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)\n",
    "\n",
    "# tensor flow website \n",
    "#fig, ax = plt.subplots()\n",
    "#plot_spectrogram(spectrogram, ax)\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "t = np.arange(len(waveform)) / 8000\n",
    "axes[0].plot(t, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.suptitle(label.title())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#online \n",
    "plt.figure()\n",
    "plt.imshow(tf.math.log(spectrogram).numpy())\n",
    "\n",
    "#youtube video \n",
    "#plt.figure(figsize=(30,20))\n",
    "#plt.imshow(tf.transpose(spectrogram)[0])\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shuffle the data such that not all gunshots are followed by gunshots, and similarly with no gunshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess) # calling preprocess method which generates spectograms\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000) # mixing training samples 1000 at the time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = data.as_numpy_iterator()\n",
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    try: \n",
    "        x_temp, y_temp = iterator.next()\n",
    "        x.append(x_temp)\n",
    "        y.append(y_temp)\n",
    "    except Exception:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build model and evaluate it's performance by doing k-Fold Cross Validation\n",
    "https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/ <br>\n",
    "https://repository.tudelft.nl/islandora/object/uuid%3A6f4f3def-f8e0-4820-8b4f-75b0254dadcd <br>\n",
    "https://stackoverflow.com/questions/50997928/typeerror-only-integer-scalar-arrays-can-be-converted-to-a-scalar-index-with-1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2 #40 \n",
    "batch = 8\n",
    "splits = 2 #10\n",
    "input = (624, 128, 1) \n",
    "# input matches with the size of data, which can be obtained as: samples,labels = data.as_numpy_iterator().next()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=123)\n",
    "acc_scores = []\n",
    "histories = []\n",
    "confusion_matrices = []\n",
    "for train, test in kfold.split(x, y):\n",
    "    # 1. Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', input_shape=input)) #matching samples.shape\n",
    "    model.add(MaxPool2D(pool_size= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 16, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size= (2,2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 2. Compile model\n",
    "    model.compile(loss=\"BinaryCrossentropy\", optimizer=keras.optimizers.legacy.SGD(learning_rate=0.01), metrics = ['accuracy', 'Recall', 'Precision']) \n",
    "    \n",
    "    # 3. Fit the model\n",
    "    x_train = np.array(x)[train.astype(int)]\n",
    "    y_train = np.array(y)[train.astype(int)]\n",
    "    x_test = np.array(x)[test.astype(int)]\n",
    "    y_test = np.array(y)[test.astype(int)]\n",
    "    \n",
    "    hist = model.fit(x_train, y_train, epochs=epoch, batch_size=batch, verbose=0, validation_data = (x_test, y_test))\n",
    "    \n",
    "    # Save information about model \n",
    "    histories.append(hist)\n",
    "    \n",
    "    # Display accuracy of validation set \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], hist.history['val_accuracy'][epoch-1] *100))\n",
    "    acc_scores.append(hist.history['val_accuracy'][epoch-1] * 100)\n",
    "\n",
    "    # Store confusion matrix \n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = [1 if prediction > 0.5 else 0 for prediction in y_pred]\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(confusion_mtx)\n",
    " \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(acc_scores), np.std(acc_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix\n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_matrix = np.mean(confusion_matrices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Gunshot' ,'No gunshot']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(mean_matrix,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Cunfusion matrix: original data')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Display and save graphs for other metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the mean of all different k-folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "list_precision = []\n",
    "list_val_precision = []\n",
    "\n",
    "list_recall = []\n",
    "list_val_recall = []\n",
    "\n",
    "list_accuracy = []\n",
    "list_val_accuracy = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    temp_loss = [ hist.history['loss'][i] for hist in histories ]\n",
    "    list_loss.append(np.mean(temp_loss))\n",
    "    temp_val_loss = [ hist.history['val_loss'][i] for hist in histories ]\n",
    "    list_val_loss.append(np.mean(temp_val_loss))\n",
    "\n",
    "    temp_precision = [ hist.history['precision'][i] for hist in histories ]\n",
    "    list_precision.append(np.mean(temp_precision))\n",
    "    temp_val_precision = [ hist.history['val_precision'][i] for hist in histories ]\n",
    "    list_val_precision.append(np.mean(temp_val_precision))\n",
    "\n",
    "    temp_recall = [ hist.history['recall'][i] for hist in histories ]\n",
    "    list_recall.append(np.mean(temp_recall))\n",
    "    temp_val_recall = [ hist.history['val_recall'][i] for hist in histories ]\n",
    "    list_val_recall.append(np.mean(temp_val_recall))\n",
    "\n",
    "    temp_accuracy = [ hist.history['accuracy'][i] for hist in histories ]\n",
    "    list_accuracy.append(np.mean(temp_accuracy))\n",
    "    temp_val_accuracy = [ hist.history['val_accuracy'][i] for hist in histories ]\n",
    "    list_val_accuracy.append(np.mean(temp_val_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss: denoised data')\n",
    "plt.plot(list_loss, 'r')\n",
    "plt.plot(list_val_loss, 'b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('loss_denoised_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision: denoised data')\n",
    "plt.plot(list_precision, 'r')\n",
    "plt.plot(list_val_precision, 'b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('precision_denoised_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall: denoised data')\n",
    "plt.plot(list_recall, 'r')\n",
    "plt.plot(list_val_recall, 'b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('recall_denoised_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy: denoised data')\n",
    "plt.plot(list_accuracy, 'r')\n",
    "plt.plot(list_val_accuracy, 'b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('accuracy_denoised_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make a single prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()\n",
    "yhat = model.predict(X_test)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.9 else 0 for prediction in yhat]\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
