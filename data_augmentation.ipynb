{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data from the elephant listening project \n",
    "general_path = os.path.join('data', 'Clips')\n",
    "\n",
    "# To ensure that both classes have same of samples and to increase the number of gunshots, \n",
    "# I extracted extra data from: https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "background_path = os.path.join('data', 'Sounds_background')\n",
    "guns_path = os.path.join('data', 'Sounds_gunshots')\n",
    "\n",
    "gunshot_files = [os.path.join(general_path, 'pnnn*'), os.path.join(general_path, 'ecoguns*'), os.path.join(guns_path, '*\\.wav')]\n",
    "\n",
    "no_gunshot_files = [os.path.join(general_path, 'other*'), os.path.join(background_path, '*\\.wav')] \n",
    "gunshot = tf.data.Dataset.list_files(gunshot_files) \n",
    "no_gunshot = tf.data.Dataset.list_files(no_gunshot_files) \n",
    "\n",
    "#to see how many files are in each group: \n",
    "#num_elements = tf.data.experimental.cardinality(no_gunshot).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and return wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name): \n",
    "    file_contents = tf.io.read_file(file_name) #retuns a string \n",
    "    wave, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # transforms string into actual wav\n",
    "    wave = wave - tf.reduce_mean(wave) # remove the mean \n",
    "    wave = wave / tf.reduce_max(tf.abs(wave)) #normalize \n",
    "    wave = tf.squeeze(wave, axis= -1) #removes axis \n",
    "    #wave = tf.cast(wave * 32768, tf.float32) # value is scaled to look like int16, however, type is kept as float32 for compatibility issues\n",
    "\n",
    "    return wave, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add labels\n",
    "1: gunshot \n",
    "0: no gunshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot = tf.data.Dataset.zip((gunshot, tf.data.Dataset.from_tensor_slices(tf.ones(len(gunshot)))))\n",
    "no_gunshot= tf.data.Dataset.zip((no_gunshot, tf.data.Dataset.from_tensor_slices(tf.zeros(len(gunshot)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concatenate gunshots and no_gunshots into one data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data/Clips/ecoguns623.wav', 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gunshot.concatenate(no_gunshot)\n",
    "data.as_numpy_iterator().next() # see how it looks like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert data into Spectogram \n",
    "Time frequency compromise: \n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio <br>\n",
    "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, TimeMask\n",
    "\n",
    "def preprocess(file_path, label): \n",
    "    # Load data\n",
    "    wave, sr = load_data(file_path)\n",
    "\n",
    "    # TODO: this returns one new sample, whereas I want 4 new ones -- Also, it shouldnt be here most likely\n",
    "    augment = Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        TimeMask(min_band_part=0.0, max_band_part= 0.1, fade = False, p = 0.5), \n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    ])  \n",
    "    augmented_samples = augment(samples=wave.numpy(), sample_rate=sr)\n",
    "    augmented_samples = tf.convert_to_tensor(augmented_samples) #conver it back to a tensor\n",
    "\n",
    "    max_lenght = 80000 # = 10* 8000, this means 10 seconds \n",
    "\n",
    "    # Padding \n",
    "    wave = wave[:max_lenght] #grab first elements up to max(lengths)\n",
    "    zero_padding = tf.zeros(max_lenght - tf.shape(wave), dtype=tf.float32) # pad with zeros what doesn't meet full length \n",
    "    wave = tf.concat([zero_padding, wave],0) \n",
    "\n",
    "    # Create spectogram \n",
    "    # 1. Fast fourier transform \n",
    "    spectrogram = tf.signal.stft(wave, frame_length=256, frame_step=128)  # Paper: 'Automated detection of gunshots in tropical forests using CNN' \n",
    "    # frame_length =  window length in samples\n",
    "    # frame_step = number of samples to step\n",
    "    # 'Time frequency compromise' \n",
    "    # if window size is small: you get good time resolution in exchange of poor frequency resolution \n",
    "\n",
    "    # 2. Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # 3. Tranform it into appropiate format for deep learning model by adding the channel dimension (in this case 1)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-1.0984945e-03  4.0011192e-04  5.7186955e-03 ... -8.9280348e-04\n",
      "  3.0447117e-03  7.6883065e-05], shape=(56109,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[-0.00179466 -0.00193992 -0.00046129 ... -0.00082526  0.00033051\n",
      " -0.00069755], shape=(56109,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/Clips/ecoguns105.wav' # seems good  \n",
    "spectrogram, label = preprocess(file_name, '1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shuffle the data such that not all gunshots are followed by gunshots, and similarly with no gunshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess) # calling preprocess method which generates spectograms\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000) # mixing training samples 1000 at the time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract samples and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 09:43:42.177877: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "iterator = data.as_numpy_iterator()\n",
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    try: \n",
    "        x_temp, y_temp = iterator.next()\n",
    "        x.append(x_temp)\n",
    "        y.append(y_temp)\n",
    "    except Exception:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 10 \n",
    "kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.621427  ]\n",
      "   [2.7231421 ]\n",
      "   [1.9626982 ]\n",
      "   ...\n",
      "   [1.2311637 ]\n",
      "   [1.1121976 ]\n",
      "   [1.0671641 ]]\n",
      "\n",
      "  [[0.71211576]\n",
      "   [1.3084363 ]\n",
      "   [2.477869  ]\n",
      "   ...\n",
      "   [0.9819437 ]\n",
      "   [0.90337455]\n",
      "   [0.46144187]]\n",
      "\n",
      "  [[0.7925458 ]\n",
      "   [1.3712667 ]\n",
      "   [1.3922966 ]\n",
      "   ...\n",
      "   [0.3787868 ]\n",
      "   [0.03888172]\n",
      "   [0.12470418]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08201611]\n",
      "   [0.37766054]\n",
      "   [0.2974698 ]\n",
      "   ...\n",
      "   [0.24561252]\n",
      "   [0.5720914 ]\n",
      "   [0.7010188 ]]\n",
      "\n",
      "  [[0.65904355]\n",
      "   [0.8838845 ]\n",
      "   [0.8720696 ]\n",
      "   ...\n",
      "   [0.4039254 ]\n",
      "   [0.3015799 ]\n",
      "   [0.5954642 ]]\n",
      "\n",
      "  [[0.64656687]\n",
      "   [0.6786211 ]\n",
      "   [0.35563478]\n",
      "   ...\n",
      "   [0.6781232 ]\n",
      "   [0.36359724]\n",
      "   [0.33372894]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.466874  ]\n",
      "   [3.3779619 ]\n",
      "   [2.932251  ]\n",
      "   ...\n",
      "   [0.06683377]\n",
      "   [0.04564839]\n",
      "   [0.04854798]]\n",
      "\n",
      "  [[4.000841  ]\n",
      "   [4.8779817 ]\n",
      "   [4.0725074 ]\n",
      "   ...\n",
      "   [0.0562012 ]\n",
      "   [0.02628687]\n",
      "   [0.02647698]]\n",
      "\n",
      "  [[0.25609785]\n",
      "   [1.1380576 ]\n",
      "   [1.3870361 ]\n",
      "   ...\n",
      "   [0.01775207]\n",
      "   [0.02230885]\n",
      "   [0.02588908]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08733959]\n",
      "   [0.05299849]\n",
      "   [0.03533553]\n",
      "   ...\n",
      "   [0.21864653]\n",
      "   [0.17638493]\n",
      "   [0.124093  ]]\n",
      "\n",
      "  [[0.08176748]\n",
      "   [0.06878638]\n",
      "   [0.08016815]\n",
      "   ...\n",
      "   [0.08824835]\n",
      "   [0.06117316]\n",
      "   [0.10426893]]\n",
      "\n",
      "  [[0.56627846]\n",
      "   [0.4144304 ]\n",
      "   [0.10085243]\n",
      "   ...\n",
      "   [0.16235888]\n",
      "   [0.12003834]\n",
      "   [0.11941792]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.09476265]\n",
      "   [0.09651465]\n",
      "   [0.27593687]\n",
      "   ...\n",
      "   [0.03191091]\n",
      "   [0.07157331]\n",
      "   [0.05825897]]\n",
      "\n",
      "  [[1.3563638 ]\n",
      "   [1.1798801 ]\n",
      "   [0.6808502 ]\n",
      "   ...\n",
      "   [0.04377644]\n",
      "   [0.01111616]\n",
      "   [0.02922821]]\n",
      "\n",
      "  [[0.3257721 ]\n",
      "   [0.24206093]\n",
      "   [0.19800927]\n",
      "   ...\n",
      "   [0.0459959 ]\n",
      "   [0.02993319]\n",
      "   [0.03602998]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28617832]\n",
      "   [0.07976716]\n",
      "   [0.20778167]\n",
      "   ...\n",
      "   [0.06427815]\n",
      "   [0.10382037]\n",
      "   [0.11198953]]\n",
      "\n",
      "  [[0.1609011 ]\n",
      "   [0.24837628]\n",
      "   [0.41233408]\n",
      "   ...\n",
      "   [0.0718812 ]\n",
      "   [0.00942601]\n",
      "   [0.02097731]]\n",
      "\n",
      "  [[0.77691215]\n",
      "   [0.5423944 ]\n",
      "   [0.14804627]\n",
      "   ...\n",
      "   [0.15478222]\n",
      "   [0.05712043]\n",
      "   [0.01771718]]]]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "from audiomentations import SpecCompose, SpecChannelShuffle, SpecFrequencyMask\n",
    "augment = SpecCompose(\n",
    "    [\n",
    "        SpecFrequencyMask(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "for train, test in kfold.split(x, y):\n",
    "    x_train = np.array(x)[train.astype(int)]\n",
    "    y_train = np.array(y)[train.astype(int)]\n",
    "    x_test = np.array(x)[test.astype(int)]\n",
    "    y_test = np.array(y)[test.astype(int)]\n",
    "\n",
    "    if counter == 0: \n",
    "        #print(x_train)\n",
    "        augmented_spectrogram = augment(x_train)\n",
    "        print('different')\n",
    "        print(augmented_spectrogram)\n",
    "    counter = counter + 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_thesis_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
