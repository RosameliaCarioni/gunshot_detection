{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import scipy.io.wavfile as wavfile\n",
    "import noisereduce as nr \n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "from scipy.interpolate import interp1d\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code was used to determine the length of the clips that are fed to the neural networks. It was also used to cut the clips larger than the decided length into the length. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code would give that there are no clips larger than 10 seconds because the clips larger than 10 seconds were removed from the files after they were handled and either cut down or splitted into new files. \n",
    "To see the original files, go to 'data/not_needed_sounds/longer_10_seconds_clips_from_ELP'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name): \n",
    "    file_contents = tf.io.read_file(file_name) #retuns a string \n",
    "    wave, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # transforms string into actual wav\n",
    "    wave = wave - tf.reduce_mean(wave) # remove the mean \n",
    "    wave = tf.squeeze(wave, axis= -1) #removes axis \n",
    "    #wave = tf.cast(wave * 32768, tf.float32) # value is scaled to look like int16, however, type is kept as float32 for compatibility issues\n",
    "\n",
    "    return wave, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "# From the elephant listening project \n",
    "counter = 0 \n",
    "for file in os.listdir(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Clips')):\n",
    "    if '.wav' in file: \n",
    "        tensor_wave, sample_rate = load_data(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Clips', file))\n",
    "        lengths.append(len(tensor_wave))\n",
    "\n",
    "# Lengths need to be divided by /sample_rate= 8000 to get their length in seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "for file in os.listdir(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Sounds_background')):\n",
    "    tensor_wave, sample_rate = load_data(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Sounds_background', file))\n",
    "    lengths.append(len(tensor_wave))\n",
    "\n",
    "for file in os.listdir(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Sounds_gunshots')):\n",
    "    if '.WAV' in file: #Adding this becuase there's a hidden file in the folder  \n",
    "        tensor_wave, sample_rate = load_data(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Sounds_gunshots', file))\n",
    "        lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = max(lengths)/8000 # the longest audio has 32.45 seconds # 259624\n",
    "mean = tf.math.reduce_mean(lengths)/8000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate how many clips longer than 10 seconds exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping up to seconds audios \n",
    "count = len([element for element in lengths if element > 10*8000])\n",
    "count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract their paths so that we can shorten them down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_greater_10 = [] # 38 \n",
    "# Only considering data from the elephant listening project, as the extra data is all 4.09 seconds long. \n",
    "for file in os.listdir(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Clips')):\n",
    "    tensor_wave, sample_rate = load_data(os.path.join('/Users', 'rosameliacarioni','University','Thesis','code','data', 'Clips', file))\n",
    "    if len(tensor_wave)> 10*8000:\n",
    "        paths_greater_10.append(file)\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new clips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in seconds \n",
    "def clip_audio_and_save_till_end (time_start, file_name, extra_name):\n",
    "    audio = AudioSegment.from_wav(file_name)\n",
    "\n",
    "    file_destintion =  file_name.replace('.wav', '') +  extra_name + '.wav'\n",
    "    second_to_milliseconds = 1000\n",
    "    time_end = len(audio) / second_to_milliseconds\n",
    "    if (time_end - time_start > 10): \n",
    "        clip = audio[time_start*second_to_milliseconds: time_start*second_to_milliseconds + 10*second_to_milliseconds]\n",
    "    else:\n",
    "        clip = audio[time_start*second_to_milliseconds: time_start*second_to_milliseconds + time_end*second_to_milliseconds]\n",
    "    \n",
    "    clip.export(file_destintion, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in seconds \n",
    "def clip_audio_and_save (time_start, time_end, file_name, extra_name):\n",
    "    audio = AudioSegment.from_wav(file_name)\n",
    "\n",
    "    file_destintion =  file_name.replace('.wav', '') +  extra_name + '.wav'\n",
    "    second_to_milliseconds = 1000\n",
    "\n",
    "    clip = audio[time_start*second_to_milliseconds: time_end*second_to_milliseconds]\n",
    "\n",
    "    clip.export(file_destintion, format='wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually looked in the lengths[] and selected the clips to extract such that:\n",
    "- For files without gunshots, similar size length clips were created\n",
    "- For files with gunshots, the entire gunshot was kept in one clip. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. other90 is divided into 2 clips of 10 seconds each\n",
    "1. other84 is divided into 2 clips of 10 seconds each\n",
    "2. other85\n",
    "3. other91 is divided into 3 clips of 10 seconds each \n",
    "4. other87 \n",
    "5. other93 is divided into 2 clips of 6 and 7 seconds \n",
    "6. other78 is divided into 3 clips of 10 seconds \n",
    "7. other1 is divided into 2 clips of 5 and 6 seconds \n",
    "8. other79 is divided into 2 clips of 10 seconds each \n",
    "9. other92 is divied into 2 clips \n",
    "10. other86 is divided into 2 clips \n",
    "11. other82 is divided into 3\n",
    "12. ecoguns839: there are 3 gunshots, so the clips will be dividede into 3\n",
    "13. other83: divided into 2  \n",
    "14. other81: divided into 2 \n",
    "15. ecoguns813: there are 6 gunshots but 3 are one next to the other, so I will divide it into 4 clips \n",
    "16. other43: divided into 2 \n",
    "17. other80: divided into 2\n",
    "18. ecoguns848:  there are 7 gunshots , divided into 4 clips \n",
    "19. ecoguns669: there are 6 gunshots, divided into 5 clips \n",
    "20. ecoguns695: there are 4 gunshots, divided into 4 clips \n",
    "21. ecoguns869: there are 5 gunshots, divided into 4 clips\n",
    "22. ecoguns663: there are 3 gunshots and the audio is just a bit longer than 10 seconds, so we keep it as 10 \n",
    "23. ecoguns931: there are 6 gunshots and the audio is about 12 seconds, so i will split it in 2 \n",
    "24. other72\n",
    "25. ecoguns822 ther are 3 gunshots and the audio is just a bit longer than 10 seconds, so we keep it as 10 \n",
    "26. other71 \n",
    "27. pnnn2: there are about 8 gunshots \n",
    "28. ecoguns763\n",
    "29. other75 \n",
    "30. other61 \n",
    "31. other49\n",
    "32. other88 \n",
    "33. other77 \n",
    "34. other63\n",
    "35. other62\n",
    "36. other76\n",
    "37. other89"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
