{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: [\"dlopen(/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): tried: '/Users/rosameliacarioni/miniconda3/envs/bach_thesis_4/lib/python3.9/site-packages/tensorflow_io-0.32.0-py3.9-macosx-11.0-arm64.egg/tensorflow_io/python/ops/libtensorflow_io.so' (no such file)\"]\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Audio Classifier using original data (no denoising has been applied)\n",
    "Following: https://www.youtube.com/watch?v=ZLIPkmmDJAc&t=1468s&ab_channel=NicholasRenotte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data from the elephant listening project \n",
    "general_path = os.path.join('data', 'Clips')\n",
    "\n",
    "# To ensure that both classes have same of samples and to increase the number of gunshots, \n",
    "# I extracted extra data from: https://data.mendeley.com/datasets/x48cwz364j/3 \n",
    "background_path = os.path.join('data', 'Sounds_background')\n",
    "guns_path = os.path.join('data', 'Sounds_gunshots')\n",
    "\n",
    "gunshot_files = [os.path.join(general_path, 'pnnn*'), os.path.join(general_path, 'ecoguns*'), os.path.join(guns_path, '*\\.wav')]\n",
    "\n",
    "no_gunshot_files = [os.path.join(general_path, 'other*'), os.path.join(background_path, '*\\.wav')] \n",
    "gunshot = tf.data.Dataset.list_files(gunshot_files) \n",
    "no_gunshot = tf.data.Dataset.list_files(no_gunshot_files) \n",
    "\n",
    "#to see how many files are in each group: \n",
    "#num_elements = tf.data.experimental.cardinality(no_gunshot).numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and return wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name): \n",
    "    file_contents = tf.io.read_file(file_name) #retuns a string \n",
    "    wave, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # transforms string into actual wav\n",
    "    wave = wave - tf.reduce_mean(wave) # remove the mean \n",
    "    wave = tf.squeeze(wave, axis= -1) #removes axis \n",
    "    #wave = tf.cast(wave * 32768, tf.float32) # value is scaled to look like int16, however, type is kept as float32 for compatibility issues\n",
    "\n",
    "    return wave, sample_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing \n",
    "file = 'data/Clips/other2.wav'\n",
    "wave, rate = load_data(file)\n",
    "#plt.plot(wave)\n",
    "file = 'data/Sounds_background/pnnn4.wav'\n",
    "wave, rate = load_data(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add labels\n",
    "1: gunshot \n",
    "0: no gunshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunshot = tf.data.Dataset.zip((gunshot, tf.data.Dataset.from_tensor_slices(tf.ones(len(gunshot)))))\n",
    "no_gunshot= tf.data.Dataset.zip((no_gunshot, tf.data.Dataset.from_tensor_slices(tf.zeros(len(gunshot)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concatenate gunshots and no_gunshots into one data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data/Clips/ecoguns990.wav', 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gunshot.concatenate(no_gunshot)\n",
    "data.as_numpy_iterator().next() # see how it looks like "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert data into Spectogram \n",
    "Time frequency compromise: \n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    # Load data\n",
    "    wave, sr = load_data(file_path)\n",
    "    max_lenght = 80000 # = 10* 8000, this means 10 seconds \n",
    "\n",
    "    # Padding \n",
    "    wave = wave[:max_lenght] #grab first elements up to max(lengths)\n",
    "    zero_padding = tf.zeros(max_lenght - tf.shape(wave), dtype=tf.float32) # pad with zeros what doesn't meet full length \n",
    "    wave = tf.concat([zero_padding, wave],0) \n",
    "\n",
    "    # Create spectogram \n",
    "    # 1. Fast fourier transform \n",
    "    spectrogram = tf.signal.stft(wave, frame_length=256, frame_step=128)  # Paper: 'Automated detection of gunshots in tropical forests using CNN' \n",
    "    # frame_length =  window length in samples\n",
    "    # frame_step = number of samples to step\n",
    "    # 'Time frequency compromise' \n",
    "    # if window size is small: you get good time resolution in exchange of poor frequency resolution \n",
    "\n",
    "    # 2. Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # 3. Tranform it into appropiate format for deep learning model by adding the channel dimension (in this case 1)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'data/Clips/ecoguns1.wav' # bad: pixeled -- and quite a few are the same (1-4)\n",
    "file_name = 'data/Clips/ecoguns105.wav' # seems good  \n",
    "file_name = 'data/Clips/pnnn4.wav'\n",
    "file_name = 'data/Clips/other1.wav'\n",
    "file_name = 'data/Sounds_gunshots/5B9FE452_38.WAV'\n",
    "file_name = 'data/Sounds_background/5B1E8AFA.WAV'\n",
    "\n",
    "\n",
    "#file_name = 'data/Clips_denoised/gunshots/spectral_gating/ecoguns0.wav'\n",
    "\n",
    "waveform, sr = load_data_2(file_name)\n",
    "spectrogram, label = preprocess(file_name, '1')\n",
    "\n",
    "# The reason the plot only shows frequencies up to 140 Hz is because the spectrogram is plotted using a log scale,\n",
    "#  which compresses higher frequencies. The pcolormesh function is plotting the spectrogram as a 2D heatmap where \n",
    "# the x-axis represents time and the y-axis represents frequency, and the color represents the magnitude of the spectrogram \n",
    "# at each time-frequency point.\n",
    "\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  t = np.arange(len(waveform)) / 8000\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)\n",
    "\n",
    "# tensor flow website \n",
    "#fig, ax = plt.subplots()\n",
    "#plot_spectrogram(spectrogram, ax)\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "t = np.arange(len(waveform)) / 8000\n",
    "axes[0].plot(t, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.suptitle(label.title())\n",
    "plt.show()\n",
    "\n",
    "#online \n",
    "#plt.figure()\n",
    "#plt.imshow(tf.math.log(spectrogram).numpy())\n",
    "\n",
    "#youtube video \n",
    "#plt.figure(figsize=(30,20))\n",
    "#plt.imshow(tf.transpose(spectrogram)[0])\n",
    "#plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Training and Testing partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "data = data.map(preprocess) # calling preprocess method which generates spectograms\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000) # mixing training samples \n",
    "data = data.batch(batch) #train at 16 samples at the time \n",
    "data = data.prefetch(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(round(len(data)*.7)) #taking 70% of the total data\n",
    "test = data.skip(round(len(data)*.7)).take(len(data) - round(len(data)*.7)) # taking remaining 30% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,labels = train.as_numpy_iterator().next()\n",
    "samples.shape\n",
    "# Input to Neural network: 624, 129, 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Deep Learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Adding layers \n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(624, 129, 1))) #matching samples.shape\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "# learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=100, validation_data=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss: original data')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('loss_original_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision: original data')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('precision_original_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall: original data')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('recall_original_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy: original data')\n",
    "plt.plot(hist.history['accuracy'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.grid()\n",
    "plt.savefig('accuracy_original_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make a prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()\n",
    "yhat = model.predict(X_test)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.9 else 0 for prediction in yhat]\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_sum(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. See how good the predictions are from the testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = test.as_numpy_iterator()\n",
    "total = 0\n",
    "true_positive = 0 \n",
    "true_negative = 0 \n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "while True:\n",
    "    try: \n",
    "        X_test, y_test = iterator.next()\n",
    "        yhat = model.predict(X_test)\n",
    "        yhat = [1 if prediction > 0.9 else 0 for prediction in yhat]\n",
    "        for prediction,result in zip(yhat, y_test):\n",
    "            if prediction == result and prediction == 1:\n",
    "               true_positive +=1 \n",
    "            elif  prediction == result and prediction == 0:\n",
    "                true_negative +=1 \n",
    "            elif prediction != result and prediction == 1:\n",
    "                false_positive +=1\n",
    "            else:\n",
    "                false_negative +=1\n",
    "    except Exception:\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = true_positive + true_negative + false_positive + false_negative \n",
    "print(total)\n",
    "print(true_positive )\n",
    "print(true_negative) \n",
    "print(false_positive) \n",
    "print(false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (true_positive+true_negative) /total\n",
    "accuracy*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
